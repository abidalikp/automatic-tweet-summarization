{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7b89OQbMxIq"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet pytorch-lightning\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuG2T6qpNyYJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import torch \n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from termcolor import colored\n",
        "import textwrap\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast as T5Tokenizer\n",
        ")\n",
        "from tqdm.auto import tqdm\n",
        "from rouge_score import rouge_scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YETDeVTPek8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "rcParams['figure.figsize'] = 16, 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_EoqUr1QR5I"
      },
      "outputs": [],
      "source": [
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VavyBwEvZ0ka"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "    df['text'] = df['text'].str.replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True) # Remove urls\n",
        "    df = df.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii')) # Remove emojis and smileys.\n",
        "    df['text'] = df['text'].str.replace('#', '').replace('@', '') # Remove hashtag and mention symbols only.\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxExvnXDa6un"
      },
      "outputs": [],
      "source": [
        "%cd drive/My Drive/PROJECT/T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6FlN-0Gp06I"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7izOeaqLqjPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrqzDTaRbVgl"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.1)\n",
        "train_df = clean_data(train_df) # cleaning the training dataset\n",
        "(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adCYTfaUogtJ"
      },
      "outputs": [],
      "source": [
        "class TweetSummaryDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        tokenizer: T5Tokenizer,\n",
        "        text_max_token_len: int = 512,\n",
        "        summary_max_token_len: int = 128):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        text = data_row[\"text\"]\n",
        "\n",
        "        text_encoding = tokenizer(\n",
        "            text,\n",
        "            max_length = self.text_max_token_len,\n",
        "            padding = \"max_length\",\n",
        "            truncation = True,\n",
        "            return_attention_mask = True,\n",
        "            add_special_tokens = True,\n",
        "            return_tensors = \"pt\"\n",
        "        )\n",
        "        \n",
        "        summary_encoding = tokenizer(\n",
        "            data_row[\"summary\"],\n",
        "            max_length = self.summary_max_token_len,\n",
        "            padding = \"max_length\",\n",
        "            truncation = True,\n",
        "            return_attention_mask = True,\n",
        "            add_special_tokens = True,\n",
        "            return_tensors = \"pt\"\n",
        "        )\n",
        "\n",
        "        labels = summary_encoding[\"input_ids\"]\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return dict(\n",
        "            text = text,\n",
        "            summary = data_row[\"summary\"],\n",
        "            text_input_ids = text_encoding[\"input_ids\"].flatten(),\n",
        "            text_attention_mask = text_encoding[\"attention_mask\"].flatten(),\n",
        "            labels = labels.flatten(),\n",
        "            labels_attention_mask = summary_encoding[\"attention_mask\"].flatten()\n",
        "        )\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlzt4TdgvtXv"
      },
      "outputs": [],
      "source": [
        "class TweetSummaryDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 train_df: pd.DataFrame,\n",
        "                 test_df: pd.DataFrame,\n",
        "                 tokenizer: T5Tokenizer,\n",
        "                 batch_size: int = 8,\n",
        "                 text_max_token_len: int = 512,\n",
        "                 summary_max_token_len: int = 128):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "\n",
        "    def setup(self, stage= None):\n",
        "\n",
        "        self.train_dataset = TweetSummaryDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "\n",
        "        self.test_dataset = TweetSummaryDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size= self.batch_size,\n",
        "            shuffle= True,\n",
        "            num_workers= 2\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size= self.batch_size,\n",
        "            num_workers= 2\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size= self.batch_size,\n",
        "            num_workers= 2\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epweai1myoU_"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"t5-base\"\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tr5Lg8B07iJ"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 4\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "data_module = TweetSummaryDataModule(train_df, test_df, tokenizer, batch_size= BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF30cmP21rph"
      },
      "outputs": [],
      "source": [
        "class TweetSummaryModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict= True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "\n",
        "        output = self.model(\n",
        "            input_ids,\n",
        "            attention_mask= attention_mask,\n",
        "            labels= labels,\n",
        "            decoder_attention_mask= decoder_attention_mask\n",
        "        )\n",
        "\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids= input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar= True, logger= True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids= input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar= True, logger= True)\n",
        "        return loss\n",
        "\n",
        "    def testing_step(self, batch, batch_idx):\n",
        "\n",
        "        input_ids = batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self(\n",
        "            input_ids= input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_attention_mask = labels_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar= True, logger= True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr= 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YqCCe4O-P-S"
      },
      "outputs": [],
      "source": [
        "load_model = TweetSummaryModel.load_from_checkpoint(checkpoint_path=\"checkpoint/epoch=40.ckpt\")\n",
        "#load_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg6Rz_qy5iJ4"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = \"checkpoints\",\n",
        "    filename = \"best-checkpoint\",\n",
        "    save_top_k = 1,\n",
        "    verbose = True,\n",
        "    monitor = \"val_loss\",\n",
        "    mode = \"min\"\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name= \"tweet-summary\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger = logger,\n",
        "    checkpoint_callback = checkpoint_callback,\n",
        "    max_epochs = N_EPOCHS,\n",
        "    gpus = 1\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTmNMoB86yTe"
      },
      "outputs": [],
      "source": [
        "%%timeit -r 1 -n 1\n",
        "trainer.fit(load_model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCNVM10l-Dum"
      },
      "outputs": [],
      "source": [
        "trained_model = TweetSummaryModel.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        ")\n",
        "\n",
        "trained_model.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBs5rIMK-Qt0"
      },
      "outputs": [],
      "source": [
        "def summarize(text):\n",
        "    \n",
        "    text_encoding = tokenizer(\n",
        "        text,\n",
        "        max_length= 1024,\n",
        "        padding= \"max_length\",\n",
        "        truncation= True,\n",
        "        return_attention_mask= True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "\n",
        "    load_model.eval()\n",
        "\n",
        "    generated_ids = load_model.model.generate(\n",
        "        input_ids = text_encoding[\"input_ids\"],\n",
        "        attention_mask= text_encoding[\"attention_mask\"],\n",
        "        max_length = 200,\n",
        "        num_beams = 2,\n",
        "        no_repeat_ngram_size = 3,\n",
        "        repetition_penalty = 2.5,\n",
        "        length_penalty = 1.0\n",
        "    )\n",
        "\n",
        "    preds = [\n",
        "     tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "     for gen_id in generated_ids\n",
        "    ]\n",
        "\n",
        "    return \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBfbdbGbAEOX"
      },
      "outputs": [],
      "source": [
        "sample_row = test_df.iloc[1]\n",
        "text = sample_row[\"text\"]\n",
        "model_summary = summarize(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_row['text']"
      ],
      "metadata": {
        "id": "jKs1wnofxyEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD91QC_YAxIw"
      },
      "outputs": [],
      "source": [
        "model_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAWgLsD0ZCXO"
      },
      "outputs": [],
      "source": [
        "sample_row[\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7BYtEj6ZVG6"
      },
      "outputs": [],
      "source": [
        "%%timeit -r 1 -n 1\n",
        "### Rouge-Metrics\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "precision_1 = 0\n",
        "precision_2 = 0\n",
        "precision_L = 0\n",
        "recall_1 = 0\n",
        "recall_2 = 0\n",
        "recall_L = 0\n",
        "fmeasure_1 = 0\n",
        "fmeasure_2 = 0\n",
        "fmeasure_L = 0\n",
        "\n",
        "test_len = len(test_df['text'])\n",
        "\n",
        "for i in range(test_len):\n",
        "\n",
        "    sample_row = test_df.iloc[i]\n",
        "    text = sample_row[\"text\"]\n",
        "    model_summary = summarize(text)\n",
        "\n",
        "    scores = scorer.score(model_summary,\n",
        "                      sample_row[\"summary\"])\n",
        "    \n",
        "    precision_1 += scores['rouge1'][0]\n",
        "    precision_2 += scores['rouge2'][0]\n",
        "    precision_L += scores['rougeL'][0]\n",
        "    recall_1 += scores['rouge1'][1]\n",
        "    recall_2 += scores['rouge2'][1]\n",
        "    recall_L += scores['rougeL'][1]\n",
        "    fmeasure_1 += scores['rouge1'][2]\n",
        "    fmeasure_2 += scores['rouge2'][2]\n",
        "    fmeasure_L += scores['rougeL'][2]\n",
        "\n",
        "    if i%15 == 0:\n",
        "        print(i//15, end=\" \")\n",
        "\n",
        "print(\"\\n\\t\\tPrecision\\tRecall\\t\\tF-Measure\")\n",
        "print(f\"Rouge-1: \\t {precision_1/test_len:.3f}\\t\\t {recall_1/test_len:.3f}\\t\\t {fmeasure_1/test_len:.3f}\")\n",
        "print(f\"Rouge-2: \\t {precision_2/test_len:.3f}\\t\\t {recall_2/test_len:.3f}\\t\\t {fmeasure_2/test_len:.3f}\")\n",
        "print(f\"Rouge-L: \\t {precision_L/test_len:.3f}\\t\\t {recall_L/test_len:.3f}\\t\\t {fmeasure_L/test_len:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdGWS0hm8UTO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}